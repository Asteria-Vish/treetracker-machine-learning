{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::053061259712:role/service-role/AmazonSageMaker-ExecutionRole-20201027T104360\n"
     ]
    }
   ],
   "source": [
    "# this is an example of how we can resume training (or to perform incremental training)\n",
    "# it follows the following example\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object_detection_pascalvoc_coco/object_detection_incremental_training.ipynb\n",
    "\n",
    "\n",
    "#%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treetracker-training-images\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'treetracker-training-images'\n",
    "print(bucket_name)\n",
    "prefix = 'imnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imnet\n"
     ]
    }
   ],
   "source": [
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813361260812.dkr.ecr.eu-central-1.amazonaws.com/object-detection:1\n",
      "eu-central-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker.image_uris as image_uris\n",
    "\n",
    "training_image = image_uris.retrieve('object-detection', sess.boto_region_name)\n",
    "\n",
    "print (training_image)\n",
    "print(sess.boto_region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "/home/ec2-user/SageMaker/treetracker-machine-learning/imnet/imnet_to_record_io\n",
      "aug_test.idx  aug_test.rec   aug_train.lst  bounding_boxes  imnet.names\n",
      "aug_test.lst  aug_train.idx  aug_train.rec  images.txt\t    original_images\n",
      "Requirement already satisfied: mxnet in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.7.0.post1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (1.19.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (2.25.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "These downloads are big and may take some time... please be patient :)\n",
      "Seems like judas raw images have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid n12513613\n",
      "Seems like the n12513613  annotations have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid. \n",
      "Raw image data and bounding boxes for judas (wnid n12513613)  finished in  4.220008850097656e-05 seconds\n",
      "Seems like palm raw images have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid n12582231\n",
      "Seems like the n12582231  annotations have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid. \n",
      "Raw image data and bounding boxes for palm (wnid n12582231)  finished in  3.24249267578125e-05 seconds\n",
      "Seems like pine raw images have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid n11608250\n",
      "Seems like the n11608250  annotations have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid. \n",
      "Raw image data and bounding boxes for pine (wnid n11608250)  finished in  3.075599670410156e-05 seconds\n",
      "Seems like fig raw images have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid n12401684\n",
      "Seems like the n12401684  annotations have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid. \n",
      "Raw image data and bounding boxes for fig (wnid n12401684)  finished in  3.0040740966796875e-05 seconds\n",
      "Seems like china tree raw images have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid n12741792\n",
      "Seems like the n12741792  annotations have already been downloaded. If you wish to redownload, delete the original directory with the corresponding wnid. \n",
      "Raw image data and bounding boxes for china tree (wnid n12741792)  finished in  3.0040740966796875e-05 seconds\n",
      "Finished generating output file\n",
      "saving lists to disk...==] 99.8% ...\n",
      "List file ./train.lst generated...\n",
      "Creating .rec file from /home/ec2-user/SageMaker/treetracker-machine-learning/imnet/imnet_to_record_io/train.lst in /home/ec2-user/SageMaker/treetracker-machine-learning/imnet/imnet_to_record_io\n",
      "Multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.12798643112182617  count: 0\n",
      "List file ./validation.lst generated...\n",
      "Creating .rec file from /home/ec2-user/SageMaker/treetracker-machine-learning/imnet/imnet_to_record_io/validation.lst in /home/ec2-user/SageMaker/treetracker-machine-learning/imnet/imnet_to_record_io\n",
      "Multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.008130073547363281  count: 0\n",
      "List file ./test.lst generated...\n",
      "Creating .rec file from /home/ec2-user/SageMaker/treetracker-machine-learning/imnet/imnet_to_record_io/test.lst in /home/ec2-user/SageMaker/treetracker-machine-learning/imnet/imnet_to_record_io\n",
      "Multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.01077723503112793  count: 0\n",
      "Record files generated.\n",
      "HEADER(flag=17, label=array([2.    , 5.    , 0.    , 0.    , 0.1787, 0.384 , 0.9973, 0.    ,\n",
      "       0.46  , 0.0347, 0.928 , 0.9973, 0.    , 0.566 , 0.2853, 0.998 ,\n",
      "       0.9947], dtype=float32), id=115, id2=0)\n",
      "Figure(640x480)\n",
      "HEADER(flag=7, label=array([2.    , 5.    , 0.    , 0.    , 0.    , 0.9947, 0.996 ],\n",
      "      dtype=float32), id=258, id2=0)\n",
      "Figure(640x480)\n",
      "HEADER(flag=7, label=array([2.    , 5.    , 0.    , 0.08  , 0.    , 0.9947, 0.996 ],\n",
      "      dtype=float32), id=233, id2=0)\n",
      "Figure(640x480)\n",
      "HEADER(flag=17, label=array([2.    , 5.    , 0.    , 0.176 , 0.0107, 0.512 , 0.816 , 0.    ,\n",
      "       0.122 , 0.512 , 0.17  , 0.6667, 0.    , 0.    , 0.5093, 0.066 ,\n",
      "       0.632 ], dtype=float32), id=185, id2=0)\n",
      "Figure(640x480)\n",
      "HEADER(flag=12, label=array([2.000e+00, 5.000e+00, 0.000e+00, 3.760e-01, 0.000e+00, 9.980e-01,\n",
      "       9.173e-01, 0.000e+00, 2.000e-03, 2.700e-03, 5.300e-01, 9.360e-01],\n",
      "      dtype=float32), id=241, id2=0)\n",
      "Figure(640x480)\n",
      "CPU times: user 286 ms, sys: 151 ms, total: 437 ms\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! rm data/train.* -rf   \n",
    "! mkdir data\n",
    "! pwd\n",
    "! ls data\n",
    "! pip install mxnet\n",
    "\n",
    "! python3 convert_imnet_to_recordio.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing to s3://treetracker-training-images/imnet/train.rec\n",
      "CPU times: user 102 µs, sys: 0 ns, total: 102 µs\n",
      "Wall time: 71.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "key_train = \"{}/train.rec\".format(prefix)\n",
    "s3_train_data = 's3://{}/{}'.format(bucket_name, key_train)\n",
    "print('Done writing to {}'.format(s3_train_data))\n",
    "\n",
    "key_validation = \"{}/validation.rec\".format(prefix)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket_name, key_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://treetracker-training-images/imnet/output\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                             role, \n",
    "                                             instance_count=1, \n",
    "                                             instance_type='ml.p3.2xlarge',\n",
    "                                             volume_size = 50,\n",
    "                                             max_run = 360000,\n",
    "                                             input_mode= 'File',\n",
    "                                             output_path=s3_output_location,\n",
    "                                             sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_species = 2 # this should be the number of lines of imnet.names\n",
    "my_training_samples = 2451\n",
    "\n",
    "new_od_model.set_hyperparameters(base_network='resnet-50',\n",
    "                                 use_pretrained_model=1,\n",
    "                                 num_classes=num_species,\n",
    "                                 mini_batch_size=32,\n",
    "                                 epochs=1,\n",
    "                                 learning_rate=0.001,\n",
    "                                 lr_scheduler_step='3,6',\n",
    "                                 lr_scheduler_factor=0.1,\n",
    "                                 optimizer='sgd',\n",
    "                                 momentum=0.9,\n",
    "                                 weight_decay=0.0005,\n",
    "                                 overlap_threshold=0.5,\n",
    "                                 nms_threshold=0.45,\n",
    "                                 image_shape=300,\n",
    "                                 label_width=350,\n",
    "                                 num_training_samples=my_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.TrainingInput(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "\n",
    "validation_data = sagemaker.session.TrainingInput(s3_validation_data, distribution='FullyReplicated', \n",
    "                              content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "\n",
    "s3_model_data = 's3://treetracker-training-images/imnet/output/tree-nontree/object-detection-2021-01-01-21-26-10-808/output/model.tar.gz'\n",
    "\n",
    "model_data = sagemaker.session.TrainingInput(s3_model_data, distribution='FullyReplicated', \n",
    "                             content_type='application/x-sagemaker-model', s3_data_type='S3Prefix')\n",
    "\n",
    "# In addition to two data channels, add a 'model' channel for the training.\n",
    "data_channels_with_initial_model = {'train': train_data, 'validation': validation_data, 'model': model_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-30 17:35:30 Starting - Starting the training job...\n",
      "2021-01-30 17:35:54 Starting - Launching requested ML instancesProfilerReport-1612028130: InProgress\n",
      "......\n",
      "2021-01-30 17:36:54 Starting - Preparing the instances for training......\n",
      "2021-01-30 17:37:55 Downloading - Downloading input data...\n",
      "2021-01-30 17:38:15 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'label_width': u'350', u'early_stopping_min_epochs': u'10', u'epochs': u'30', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'32', u'use_pretrained_model': u'0', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'num_training_samples': u'', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'', u'base_network': u'vgg-16', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'300'}\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.001', u'epochs': u'1', u'nms_threshold': u'0.45', u'optimizer': u'sgd', u'base_network': u'resnet-50', u'image_shape': u'300', u'label_width': u'350', u'lr_scheduler_step': u'3,6', u'momentum': u'0.9', u'overlap_threshold': u'0.5', u'num_training_samples': u'2451', u'mini_batch_size': u'32', u'weight_decay': u'0.0005', u'use_pretrained_model': u'1', u'num_classes': u'2', u'lr_scheduler_factor': u'0.1'}\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Final configuration: {u'label_width': u'350', u'early_stopping_min_epochs': u'10', u'epochs': u'1', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'32', u'use_pretrained_model': u'1', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'3,6', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'num_training_samples': u'2451', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'2', u'base_network': u'resnet-50', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'300'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Using default worker.\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Loaded iterator creator application/x-image for content type ('application/x-image', '1.0')\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Loaded iterator creator application/x-recordio for content type ('application/x-recordio', '1.0')\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Loaded iterator creator image/png for content type ('image/png', '1.0')\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Loaded iterator creator image/jpeg for content type ('image/jpeg', '1.0')\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] nvidia-smi took: 0.0754909515381 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 INFO 139721585260352] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:38 WARNING 139721585260352] Training images are resized to image shape (3, 300, 300)\u001b[0m\n",
      "\u001b[34m[17:38:38] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, use 7 threads for decoding..\u001b[0m\n",
      "\u001b[34m[17:38:38] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, label padding width: 350\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:40 WARNING 139721585260352] Validation images are resized to image shape (3, 300, 300)\u001b[0m\n",
      "\u001b[34m[17:38:40] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/validation/validation.rec, use 7 threads for decoding..\u001b[0m\n",
      "\u001b[34m[17:38:40] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/validation/validation.rec, label padding width: 350\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:42 INFO 139721585260352] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:42 INFO 139721585260352] Using [gpu(0)] as training context.\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:42 INFO 139721585260352] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:42 INFO 139721585260352] Create Store: device\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:42 INFO 139721585260352] Using (gpu(0)) as training context.\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:42 INFO 139721585260352] Start training from the model in the model channel.\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:42 INFO 139721585260352] Found a model archive file. Extracting model.tar.gz\u001b[0m\n",
      "\n",
      "2021-01-30 17:38:56 Training - Training image download completed. Training in progress.\u001b[34m[01/30/2021 17:38:46 INFO 139721585260352] Using model weights from file /tmp/tmpiQIYTj/model_algo_1.\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:46 INFO 139721585260352] done loading checkpoint\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:38:57 INFO 139721585260352] Creating a new state instance.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1612028337.653553, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1612028337.653468}\n",
      "\u001b[0m\n",
      "\u001b[34m[17:38:57] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\n",
      "2021-01-30 17:39:28 Uploading - Uploading generated training model\u001b[34m[01/30/2021 17:39:23 INFO 139721585260352] #quality_metric: host=algo-1, epoch=0, batch=77 train cross_entropy <loss>=(0.17208030842105437)\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:23 INFO 139721585260352] #quality_metric: host=algo-1, epoch=0, batch=77 train smooth_l1 <loss>=(0.07166809719998843)\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:23 INFO 139721585260352] Round of batches complete\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:23 INFO 139721585260352] Updated the metrics\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:25 INFO 139721585260352] #quality_metric: host=algo-1, epoch=0, validation mAP <score>=(0.5569342478407939)\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:25 INFO 139721585260352] Updating the best model with validation-mAP=0.5569342478407939\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:25 INFO 139721585260352] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:25 INFO 139721585260352] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1612028365.122066, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 0}, \"StartTime\": 1612028337.65389}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:25 WARNING 139721585260352] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:25 INFO 139721585260352] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2021 17:39:25 INFO 139721585260352] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"totaltime\": {\"count\": 1, \"max\": 47542.52815246582, \"sum\": 47542.52815246582, \"min\": 47542.52815246582}, \"setuptime\": {\"count\": 1, \"max\": 11.169195175170898, \"sum\": 11.169195175170898, \"min\": 11.169195175170898}}, \"EndTime\": 1612028365.787267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1612028318.362402}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-01-30 17:39:57 Completed - Training job completed\n",
      "ProfilerReport-1612028130: NoIssuesFound\n",
      "Training seconds: 121\n",
      "Billable seconds: 121\n"
     ]
    }
   ],
   "source": [
    "new_od_model.fit(inputs=data_channels_with_initial_model, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "object_detector = new_od_model.deploy(initial_instance_count = 1,\n",
    "                                 instance_type = 'ml.m4.xlarge')\n",
    "object_detector.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from image_utils import visualize_detection\n",
    "\n",
    "def compute_detections(file_name):\n",
    "    with open(file_name, 'rb') as image:\n",
    "        f = image.read()\n",
    "        b = bytearray(f)\n",
    "        ne = open('n.txt','wb')\n",
    "        ne.write(b)\n",
    "\n",
    "    results = object_detector.predict(b, initial_args={'ContentType': 'image/jpeg'})\n",
    "    detections = json.loads(results)\n",
    "    # print (detections)\n",
    "\n",
    "    # Setting a threshold 0.20 will only plot detection results that have a confidence score greater than 0.20.\n",
    "    object_categories = ['tree', 'nontree']\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Visualize the detections.\n",
    "    visualize_detection(file_name, detections['prediction'], object_categories, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = []\n",
    "file_name.append('data/original_images/judas/n12513613_7251.JPEG')\n",
    "file_name.append('data/original_images/judas/n12513613_7922.JPEG')\n",
    "file_name.append('data/original_images/judas/n12513613_4910.JPEG')\n",
    "file_name.append('data/original_images/fig/n12401684_10111.JPEG')\n",
    "file_name.append('data/original_images/fig/n12401684_23162.JPEG')\n",
    "file_name.append('data/original_images/fig/n12401684_2691.JPEG')\n",
    "file_name.append('data/original_images/palm/n12582231_26277.JPEG')\n",
    "file_name.append('data/original_images/palm/n12582231_23552.JPEG')\n",
    "file_name.append('data/original_images/palm/n12582231_10693.JPEG')\n",
    "file_name.append('data/original_images/pine/n11608250_21659.JPEG')\n",
    "file_name.append('data/original_images/pine/n11608250_24462.JPEG')\n",
    "file_name.append('data/original_images/pine/n11608250_11636.JPEG')\n",
    "file_name.append('data/original_images/china tree/n12741792_12058.JPEG')\n",
    "file_name.append('data/original_images/china tree/n12741792_4736.JPEG')\n",
    "file_name.append('data/original_images/china tree/n12741792_693.JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/original_images/judas/n12513613_7251.JPEG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e4ecc8ddc4b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcompute_detections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-107fd95e986c>\u001b[0m in \u001b[0;36mcompute_detections\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_detections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/original_images/judas/n12513613_7251.JPEG'"
     ]
    }
   ],
   "source": [
    "for file in file_name:\n",
    "    compute_detections(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
