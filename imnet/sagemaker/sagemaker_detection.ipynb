{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version is good\n",
      "Region = eu-central-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "# from sagemaker.image_uris import retrieve\n",
    "from sagemaker.s3 import *\n",
    "import sys\n",
    "\n",
    "if int(sagemaker.__version__.split('.')[0]) == 2:\n",
    "    !{sys.executable} -m pip install sagemaker==1.72.0\n",
    "    print(\"Installing previous SageMaker Version. Please restart the kernel\")\n",
    "else:\n",
    "    print(\"Version is good\")\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=None)\n",
    "region = boto3.session.Session().region_name\n",
    "print(\"Region = {}\".format(region))\n",
    "\n",
    "sm = boto3.Session().client('sagemaker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.6.0-gpu-py36-cu101-ubuntu16.04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# see https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html for which inputs to use\n",
    "# see https://github.com/aws/deep-learning-containers/blob/master/available_images.md for registry paths with custom algorithms\n",
    "\n",
    "\n",
    "training_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.6.0-gpu-py36-cu101-ubuntu16.04\"\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker-experiments in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.1.25)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-experiments) (1.16.37)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.19.37)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.16.27->sagemaker-experiments) (1.25.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.37->boto3>=1.16.27->sagemaker-experiments) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-experiments \n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawbucket= sess.default_bucket() # Alternatively you can use our custom bucket here. \n",
    "data_bucket = \"treetracker-training-images\"\n",
    "prefix = 'sagemaker-modelmonitor' # use this prefix to store all files pertaining to this workshop.\n",
    "\n",
    "dataprefix = prefix + '/data'\n",
    "traindataprefix = prefix + '/train_data'\n",
    "testdataprefix = prefix + '/test_data'\n",
    "testdatanolabelprefix = prefix + '/test_data_no_label'\n",
    "trainheaderprefix = prefix + '/train_headers'\n",
    "\n",
    "s3_train_key = \"imnet\"\n",
    "s3_validation_key = \"\"\n",
    "s3_train = 's3://{}/{}/'.format(data_bucket, s3_train_key)\n",
    "s3_validation = 's3://{}/{}/'.format(data_bucket, s3_validation_key)\n",
    "sagemaker_train = 's3://{}/{}/'.format(rawbucket, s3_train_key)\n",
    "sagemaker_validation = 's3://{}/{}/'.format(rawbucket, s3_validation_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data location = sagemaker-eu-central-1-053061259712/sagemaker-modelmonitor/train_data\n",
      "Test data location = sagemaker-eu-central-1-053061259712/sagemaker-modelmonitor/test_data\n"
     ]
    }
   ],
   "source": [
    "train_data_location = rawbucket + '/' + traindataprefix\n",
    "test_data_location = rawbucket+'/'+testdataprefix\n",
    "print(\"Training data location = {}\".format(train_data_location))\n",
    "print(\"Test data location = {}\".format(test_data_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out preprocessing instance jobs\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "pre_input = ProcessingInput(source=s3_train, destination=None, input_name=\"pre\")\n",
    "pre_output = ProcessingOutput(source=None, destination=sagemaker_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# This is where you can add hyperparameters, framework used, point to the script, and define instances you want to train on. \n",
    "# ALl of this information is represented as environment variables passed to the instance. In your script, you can refer to these variables or \n",
    "# the argument. \n",
    "estimator = PyTorch(entry_point='mobilenet_v2.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.4.0',\n",
    "                    train_instance_count=2,\n",
    "                    train_instance_type='ml.g4dn.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 5,\n",
    "                        'backend': 'gloo',\n",
    "                        'train_split': 0.7, \n",
    "                        'log_interval': 200\n",
    "                    },\n",
    "                   \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-12-16-02-39-05-152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-16 02:39:05 Starting - Starting the training job...\n",
      "2020-12-16 02:39:07 Starting - Launching requested ML instances......\n",
      "2020-12-16 02:40:30 Starting - Preparing the instances for training......\n",
      "2020-12-16 02:41:25 Downloading - Downloading input data....................................\n",
      "2020-12-16 02:47:29 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:29,670 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:29,696 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:32,758 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:33,070 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:33,070 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:33,070 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:33,071 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:30,261 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:30,280 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:33,302 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:33,625 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:33,626 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:33,626 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:33,626 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /tmp/tmprs1edb2w/module_dir\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=16565 sha256=599b212b786d8319d393b01fae0149a51ddfdbaff42464fff6d82ea77324e9f0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-oom8c8g5/wheels/fe/16/48/ffe0657a01537a11f8404ce5f0f7d86a83a2319943f0b79d24\u001b[0m\n",
      "\u001b[35mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpi65pwgs9/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=16565 sha256=599b212b786d8319d393b01fae0149a51ddfdbaff42464fff6d82ea77324e9f0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5juym0na/wheels/c5/69/94/d1a2a4a322fb603e5d268b6de24f156c2b69b465c188126be6\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[35mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[35mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\u001b[0m\n",
      "\u001b[35mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[35m2020-12-16 02:47:35,101 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_split\": 0.7,\n",
      "        \"backend\": \"gloo\",\n",
      "        \"log_interval\": 200,\n",
      "        \"epochs\": 5\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2020-12-16-02-39-05-152\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-053061259712/pytorch-training-2020-12-16-02-39-05-152/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mobilenet_v2\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mobilenet_v2.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"backend\":\"gloo\",\"epochs\":5,\"log_interval\":200,\"train_split\":0.7}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mobilenet_v2.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mobilenet_v2\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-eu-central-1-053061259712/pytorch-training-2020-12-16-02-39-05-152/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":5,\"log_interval\":200,\"train_split\":0.7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2020-12-16-02-39-05-152\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-053061259712/pytorch-training-2020-12-16-02-39-05-152/source/sourcedir.tar.gz\",\"module_name\":\"mobilenet_v2\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mobilenet_v2.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"5\",\"--log_interval\",\"200\",\"--train_split\",\"0.7\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_TRAIN_SPLIT=0.7\u001b[0m\n",
      "\u001b[35mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[35mSM_HP_LOG_INTERVAL=200\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python mobilenet_v2.py --backend gloo --epochs 5 --log_interval 200 --train_split 0.7\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-12-16 02:47:35,599 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_split\": 0.7,\n",
      "        \"backend\": \"gloo\",\n",
      "        \"log_interval\": 200,\n",
      "        \"epochs\": 5\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-12-16-02-39-05-152\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-053061259712/pytorch-training-2020-12-16-02-39-05-152/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mobilenet_v2\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mobilenet_v2.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":5,\"log_interval\":200,\"train_split\":0.7}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mobilenet_v2.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mobilenet_v2\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-053061259712/pytorch-training-2020-12-16-02-39-05-152/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":5,\"log_interval\":200,\"train_split\":0.7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-16-02-39-05-152\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-053061259712/pytorch-training-2020-12-16-02-39-05-152/source/sourcedir.tar.gz\",\"module_name\":\"mobilenet_v2\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mobilenet_v2.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"5\",\"--log_interval\",\"200\",\"--train_split\",\"0.7\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_SPLIT=0.7\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_INTERVAL=200\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python mobilenet_v2.py --backend gloo --epochs 5 --log_interval 200 --train_split 0.7\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mDistributed training - True\u001b[0m\n",
      "\u001b[35mNumber of gpus available - 1\u001b[0m\n",
      "\u001b[34mDistributed training - True\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 1\u001b[0m\n",
      "\u001b[35mInitialized the distributed environment: 'gloo' backend on 2 nodes. Current host rank is 1. Number of gpus: 1\u001b[0m\n",
      "\u001b[35mStarting at epoch 0\u001b[0m\n",
      "\u001b[35m==================================================\u001b[0m\n",
      "\u001b[35mEPOCH 1\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'gloo' backend on 2 nodes. Current host rank is 0. Number of gpus: 1\u001b[0m\n",
      "\u001b[34mStarting at epoch 0\u001b[0m\n",
      "\u001b[34m==================================================\u001b[0m\n",
      "\u001b[34mEPOCH 1\u001b[0m\n",
      "\u001b[35m[2020-12-16 02:47:42.282 algo-2:42 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2020-12-16 02:47:42.283 algo-2:42 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2020-12-16 02:47:42.283 algo-2:42 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2020-12-16 02:47:42.283 algo-2:42 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35m[2020-12-16 02:47:42.285 algo-2:42 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-12-16 02:47:42.089 algo-1:42 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-12-16 02:47:42.090 algo-1:42 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-12-16 02:47:42.090 algo-1:42 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-12-16 02:47:42.090 algo-1:42 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-12-16 02:47:42.092 algo-1:42 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 200/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 40559.945\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.004\u001b[0m\n",
      "\u001b[34mBBox RMSE: 558.643\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.206\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 200/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 39840.652\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.004\u001b[0m\n",
      "\u001b[35mBBox RMSE: 552.040\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.194\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 316/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 50781.785\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.003\u001b[0m\n",
      "\u001b[34mBBox RMSE: 619.267\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.151\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 316/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 49539.523\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.003\u001b[0m\n",
      "\u001b[35mBBox RMSE: 607.970\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.143\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 400/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 65558.430\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.002\u001b[0m\n",
      "\u001b[34mBBox RMSE: 694.543\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.146\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 400/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 64559.578\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.002\u001b[0m\n",
      "\u001b[35mBBox RMSE: 684.035\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.130\u001b[0m\n",
      "\u001b[34mVALIDATION EPOCH  1\u001b[0m\n",
      "\u001b[35mVALIDATION EPOCH  1\u001b[0m\n",
      "\u001b[34mBatch Average Val Loss: 128545.836\u001b[0m\n",
      "\u001b[34mBatch Avg Val Classification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBatch Avg Val BBox RMSE: 1012.501\u001b[0m\n",
      "\u001b[34mBatch Avg Avg Bbox IoU: 0.000 \n",
      "\u001b[0m\n",
      "\u001b[34mEpoch  2  finished in  474.2975037097931\u001b[0m\n",
      "\u001b[34m==================================================\u001b[0m\n",
      "\u001b[34mEPOCH 2\u001b[0m\n",
      "\u001b[35mBatch Average Val Loss: 138379.391\u001b[0m\n",
      "\u001b[35mBatch Avg Val Classification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBatch Avg Val BBox RMSE: 1050.642\u001b[0m\n",
      "\u001b[35mBatch Avg Avg Bbox IoU: 0.000 \n",
      "\u001b[0m\n",
      "\u001b[35mEpoch  2  finished in  480.2804641723633\u001b[0m\n",
      "\u001b[35m==================================================\u001b[0m\n",
      "\u001b[35mEPOCH 2\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 200/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 154635.781\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBBox RMSE: 1103.148\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.035\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 200/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 167380.375\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBBox RMSE: 1129.627\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.004\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 316/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 159653.562\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.001\u001b[0m\n",
      "\u001b[34mBBox RMSE: 1122.780\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.037\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 316/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 159938.156\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.001\u001b[0m\n",
      "\u001b[35mBBox RMSE: 1106.599\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.034\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 400/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 178804.281\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.001\u001b[0m\n",
      "\u001b[34mBBox RMSE: 1184.045\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.029\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 400/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 189600.000\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.001\u001b[0m\n",
      "\u001b[35mBBox RMSE: 1199.481\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.027\u001b[0m\n",
      "\u001b[34mVALIDATION EPOCH  2\u001b[0m\n",
      "\u001b[35mVALIDATION EPOCH  2\u001b[0m\n",
      "\u001b[34mBatch Average Val Loss: 161308.375\u001b[0m\n",
      "\u001b[34mBatch Avg Val Classification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBatch Avg Val BBox RMSE: 1133.860\u001b[0m\n",
      "\u001b[34mBatch Avg Avg Bbox IoU: 0.005 \n",
      "\u001b[0m\n",
      "\u001b[34mEpoch  3  finished in  460.387818813324\u001b[0m\n",
      "\u001b[34m==================================================\u001b[0m\n",
      "\u001b[34mEPOCH 3\u001b[0m\n",
      "\u001b[35mBatch Average Val Loss: 108627.914\u001b[0m\n",
      "\u001b[35mBatch Avg Val Classification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBatch Avg Val BBox RMSE: 929.826\u001b[0m\n",
      "\u001b[35mBatch Avg Avg Bbox IoU: 0.001 \n",
      "\u001b[0m\n",
      "\u001b[35mEpoch  3  finished in  468.4008004665375\u001b[0m\n",
      "\u001b[35m==================================================\u001b[0m\n",
      "\u001b[35mEPOCH 3\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 200/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 261853.453\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBBox RMSE: 1436.218\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.050\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 200/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 273258.719\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBBox RMSE: 1444.826\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.021\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 316/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 258283.719\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBBox RMSE: 1425.768\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.033\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 316/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 255927.031\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBBox RMSE: 1393.664\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.033\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 400/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 289286.062\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBBox RMSE: 1504.402\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.026\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 400/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 300459.750\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBBox RMSE: 1506.741\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.026\u001b[0m\n",
      "\u001b[34mVALIDATION EPOCH  3\u001b[0m\n",
      "\u001b[35mVALIDATION EPOCH  3\u001b[0m\n",
      "\u001b[34mBatch Average Val Loss: 194666.484\u001b[0m\n",
      "\u001b[34mBatch Avg Val Classification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBatch Avg Val BBox RMSE: 1246.178\u001b[0m\n",
      "\u001b[34mBatch Avg Avg Bbox IoU: 0.001 \n",
      "\u001b[0m\n",
      "\u001b[34mEpoch  4  finished in  461.17973160743713\u001b[0m\n",
      "\u001b[34m==================================================\u001b[0m\n",
      "\u001b[34mEPOCH 4\u001b[0m\n",
      "\u001b[35mBatch Average Val Loss: 128537.641\u001b[0m\n",
      "\u001b[35mBatch Avg Val Classification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBatch Avg Val BBox RMSE: 1011.964\u001b[0m\n",
      "\u001b[35mBatch Avg Avg Bbox IoU: 0.000 \n",
      "\u001b[0m\n",
      "\u001b[35mEpoch  4  finished in  469.0221164226532\u001b[0m\n",
      "\u001b[35m==================================================\u001b[0m\n",
      "\u001b[35mEPOCH 4\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 200/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 380891.594\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBBox RMSE: 1719.607\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.040\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 200/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 395079.812\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBBox RMSE: 1718.948\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.003\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 316/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 334792.094\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBBox RMSE: 1609.192\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.035\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 316/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 327325.656\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBBox RMSE: 1553.371\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.033\u001b[0m\n",
      "\u001b[34mLast Batch Avg Metrics, Batch 400/316.0\u001b[0m\n",
      "\u001b[34mTotal Loss: 357025.688\u001b[0m\n",
      "\u001b[34mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBBox RMSE: 1662.465\u001b[0m\n",
      "\u001b[34mAvg Bbox IoU: 0.027\u001b[0m\n",
      "\u001b[35mLast Batch Avg Metrics, Batch 400/316.0\u001b[0m\n",
      "\u001b[35mTotal Loss: 352313.625\u001b[0m\n",
      "\u001b[35mClassification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBBox RMSE: 1618.415\u001b[0m\n",
      "\u001b[35mAvg Bbox IoU: 0.026\u001b[0m\n",
      "\u001b[34mVALIDATION EPOCH  4\u001b[0m\n",
      "\u001b[35mVALIDATION EPOCH  4\u001b[0m\n",
      "\u001b[34mBatch Average Val Loss: 544178.750\u001b[0m\n",
      "\u001b[34mBatch Avg Val Classification Acc: 0.000\u001b[0m\n",
      "\u001b[34mBatch Avg Val BBox RMSE: 2084.757\u001b[0m\n",
      "\u001b[34mBatch Avg Avg Bbox IoU: 0.000 \n",
      "\u001b[0m\n",
      "\u001b[34mEpoch  5  finished in  461.0833411216736\u001b[0m\n",
      "\u001b[34mFinal checkpoint created. Model dict and metrics saved. \u001b[0m\n",
      "\u001b[34m[2020-12-16 03:18:38.229 algo-1:42 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-12-16 03:18:38,598 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-12-16 03:19:07 Uploading - Uploading generated training model\u001b[35mBatch Average Val Loss: 634776.062\u001b[0m\n",
      "\u001b[35mBatch Avg Val Classification Acc: 0.000\u001b[0m\n",
      "\u001b[35mBatch Avg Val BBox RMSE: 2251.597\u001b[0m\n",
      "\u001b[35mBatch Avg Avg Bbox IoU: 0.000 \n",
      "\u001b[0m\n",
      "\u001b[35mEpoch  5  finished in  466.8553800582886\u001b[0m\n",
      "\u001b[35mFinal checkpoint created. Model dict and metrics saved. \u001b[0m\n",
      "\u001b[35m[2020-12-16 03:19:05.840 algo-2:42 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[35m2020-12-16 03:19:06,205 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-12-16 03:19:15 Completed - Training job completed\n",
      "Training seconds: 4540\n",
      "Billable seconds: 4540\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": s3_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
