{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install monai\n",
    "!pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import yaml\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "from utils import set_seed, load_model, save, get_model, update_optimizer, get_data\n",
    "from epoch import train_epoch, val_epoch, test_epoch\n",
    "import cli\n",
    "import greenstand_utils as gu  # GREENSTAND\n",
    "from monai.losses import FocalLoss # GREENSTAND\n",
    "from ray import air, tune # GREENSTAND\n",
    "from ray.tune.schedulers import ASHAScheduler # GREENSTAND\n",
    "\n",
    "def load_config_file(hyperparameter_config_file='hyperparameters.yaml'):\n",
    "    with open(hyperparameter_config_file) as file:\n",
    "        contents = yaml.safe_load(file)\n",
    "    return contents\n",
    "\n",
    "def get_args(contents):\n",
    "    new_args = []\n",
    "    for item in contents:\n",
    "        new_args.append('--' + item)\n",
    "        new_args.append(str(contents[item]))\n",
    "    return new_args\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    set_seed(args, use_gpu=torch.cuda.is_available())\n",
    "    \n",
    "    # Get Data  # GREENSTAND\n",
    "    g_args = vars(args) # GREENSTAND\n",
    "    g_args['prefixes'] = g_args['prefixes'].split(',') # GREENSTAND\n",
    "    train_loader, val_loader, test_loader, dataset_attributes = gu.sync_split_get_dataloaders(vars(args), True)  # GREENSTAND\n",
    "    print(f\"Dataset Attributes: {dataset_attributes}\") # GREENSTANDS\n",
    "\n",
    "    model = gu.load_preloaded_model(args, dataset_attributes)  # GREENSTAND - Get pretrained model if specified \n",
    "    \n",
    "    # GREENSTAND - Choose loss\n",
    "    if args.use_focal_loss == 'y':\n",
    "        criteria = FocalLoss(to_onehot_y=True) #BinaryFocalLossWithLogits(alpha=1.0)\n",
    "    else: \n",
    "        criteria = CrossEntropyLoss()\n",
    "\n",
    "    if args.use_gpu:\n",
    "        torch.cuda.set_device(0)\n",
    "        model.cuda()\n",
    "        criteria.cuda()\n",
    "\n",
    "    # GREENSTAND - Choose Optimizer\n",
    "    if args.use_adam_optimizer == 'y':\n",
    "        optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=args.mu)\n",
    "    else:\n",
    "        optimizer = SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=args.mu, nesterov=True)\n",
    "\n",
    "    # Containers for storing metrics over epochs\n",
    "    loss_train, acc_train, topk_acc_train = [], [], []\n",
    "    loss_val, acc_val, topk_acc_val, avgk_acc_val, class_acc_val = [], [], [], [], []\n",
    "\n",
    "    save_name = args.save_name_xp.strip()\n",
    "    save_dir = os.path.join(os.getcwd(), 'results', save_name)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    print('args.k : ', args.k)\n",
    "\n",
    "    lmbda_best_acc = None\n",
    "    best_val_acc = float('-inf')\n",
    "\n",
    "    for epoch in tqdm(range(args.n_epochs), desc='epoch', position=0):\n",
    "        t = time.time()\n",
    "        optimizer = update_optimizer(optimizer, lr_schedule=dataset_attributes['lr_schedule'], epoch=epoch)\n",
    "\n",
    "        loss_epoch_train, acc_epoch_train, topk_acc_epoch_train = train_epoch(model, optimizer, train_loader,\n",
    "                                                                              criteria, loss_train, acc_train,\n",
    "                                                                              topk_acc_train, args.k,\n",
    "                                                                              dataset_attributes['n_train'],\n",
    "                                                                              args.use_gpu)\n",
    "\n",
    "        loss_epoch_val, acc_epoch_val, topk_acc_epoch_val, \\\n",
    "        avgk_acc_epoch_val, lmbda_val = val_epoch(model, val_loader, criteria,\n",
    "                                                  loss_val, acc_val, topk_acc_val, avgk_acc_val,\n",
    "                                                  class_acc_val, args.k, dataset_attributes, args.use_gpu)\n",
    "        # Send the current training result back to Tune\n",
    "        print(list(avgk_acc_epoch_val.values())[0])\n",
    "        tune.report(mean_accuracy=list(avgk_acc_epoch_val.values())[0])\n",
    "\n",
    "        # save model at every epoch\n",
    "        save(model, optimizer, epoch, os.path.join(save_dir, save_name + '_weights.tar'))\n",
    "\n",
    "        # save model with best val accuracy\n",
    "        if acc_epoch_val > best_val_acc:\n",
    "            best_val_acc = acc_epoch_val\n",
    "            lmbda_best_acc = lmbda_val\n",
    "            save(model, optimizer, epoch, os.path.join(save_dir, save_name + '_weights_best_acc.tar'))\n",
    "\n",
    "        print()\n",
    "        print(f'epoch {epoch} took {time.time()-t:.2f}')\n",
    "        print(f'loss_train : {loss_epoch_train}')\n",
    "        print(f'loss_val : {loss_epoch_val}')\n",
    "        print(f'acc_train : {acc_epoch_train} / topk_acc_train : {topk_acc_epoch_train}')\n",
    "        print(f'acc_val : {acc_epoch_val} / topk_acc_val : {topk_acc_epoch_val} / '\n",
    "              f'avgk_acc_val : {avgk_acc_epoch_val}')\n",
    "\n",
    "    # load weights corresponding to best val accuracy and evaluate on test\n",
    "    load_model(model, os.path.join(save_dir, save_name + '_weights_best_acc.tar'), args.use_gpu)\n",
    "    loss_test_ba, acc_test_ba, topk_acc_test_ba, \\\n",
    "    avgk_acc_test_ba, class_acc_test, confuse = test_epoch(model, test_loader, criteria, args.k,\n",
    "                                                  lmbda_best_acc, args.use_gpu,\n",
    "                                                  dataset_attributes)\n",
    "    \n",
    "    print(\"Average test accuracy: {}\".format(avgk_acc_test_ba))\n",
    "    print(\"Average class accuracies: {}\".format(class_acc_test))\n",
    "    display(confuse)\n",
    "\n",
    "    # Save the results as a dictionary and save it as a pickle file in desired location\n",
    "\n",
    "    results = {'loss_train': loss_train, 'acc_train': acc_train, 'topk_acc_train': topk_acc_train,\n",
    "               'loss_val': loss_val, 'acc_val': acc_val, 'topk_acc_val': topk_acc_val, 'class_acc_val': class_acc_val,\n",
    "               'avgk_acc_val': avgk_acc_val,\n",
    "               'test_results': {'loss': loss_test_ba,\n",
    "                                'accuracy': acc_test_ba,\n",
    "                                'topk_accuracy': topk_acc_test_ba,\n",
    "                                'avgk_accuracy': avgk_acc_test_ba,\n",
    "                                'class_acc_dict': class_acc_test},\n",
    "               'params': args.__dict__}\n",
    "\n",
    "    \n",
    "    with open(os.path.join(save_dir, save_name + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "        \n",
    "    return acc_test_ba\n",
    "        \n",
    "def predict(args):\n",
    "    set_seed(args, use_gpu=torch.cuda.is_available())\n",
    "    \n",
    "    # Get Data  # GREENSTAND\n",
    "    g_args = vars(args) # GREENSTAND\n",
    "    g_args['prefixes'] = g_args['prefixes'].split(',') # GREENSTAND\n",
    "    train_loader, val_loader, test_loader, dataset_attributes = gu.sync_split_get_dataloaders(vars(args), (g_args['skip_sync']=='y'))  # GREENSTAND\n",
    "    print(f\"Dataset Attributes: {dataset_attributes}\") # GREENSTANDS\n",
    "\n",
    "    model = gu.load_preloaded_model_prediction(args, dataset_attributes)  # GREENSTAND - Get pretrained model if specified \n",
    "    \n",
    "    # GREENSTAND - Choose loss\n",
    "    if args.use_focal_loss == 'y':\n",
    "        criteria = FocalLoss(to_onehot_y=True) #BinaryFocalLossWithLogits(alpha=1.0)\n",
    "    else: \n",
    "        criteria = CrossEntropyLoss()\n",
    "\n",
    "    if args.use_gpu:\n",
    "        torch.cuda.set_device(0)\n",
    "        model.cuda()\n",
    "        criteria.cuda()\n",
    "\n",
    "    # GREENSTAND - Choose Optimizer\n",
    "    if args.use_adam_optimizer == 'y':\n",
    "        optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=args.mu)\n",
    "    else:\n",
    "        optimizer = SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=args.mu, nesterov=True)\n",
    "\n",
    "    # Containers for storing metrics over epochs\n",
    "    loss_train, acc_train, topk_acc_train = [], [], []\n",
    "    loss_val, acc_val, topk_acc_val, avgk_acc_val, class_acc_val = [], [], [], [], []\n",
    "\n",
    "    lmbda_best_acc = None\n",
    "    best_val_acc = float('-inf')\n",
    "\n",
    "    # load weights corresponding to best val accuracy and evaluate on test\n",
    "    loss_test_ba, acc_test_ba, topk_acc_test_ba, \\\n",
    "    avgk_acc_test_ba, class_acc_test, confuse = test_epoch(model, test_loader, criteria, args.k,\n",
    "                                                  lmbda_best_acc, args.use_gpu,\n",
    "                                                  dataset_attributes)\n",
    "    \n",
    "    print(\"Average test accuracy: {}\".format(avgk_acc_test_ba))\n",
    "    print(\"Average class accuracies: {}\".format(class_acc_test))\n",
    "    display(confuse)\n",
    "\n",
    "    # Save the results as a dictionary and save it as a pickle file in desired location\n",
    "\n",
    "    results = {'loss_train': loss_train, 'acc_train': acc_train, 'topk_acc_train': topk_acc_train,\n",
    "               'loss_val': loss_val, 'acc_val': acc_val, 'topk_acc_val': topk_acc_val, 'class_acc_val': class_acc_val,\n",
    "               'avgk_acc_val': avgk_acc_val,\n",
    "               'test_results': {'loss': loss_test_ba,\n",
    "                                'accuracy': acc_test_ba,\n",
    "                                'topk_accuracy': topk_acc_test_ba,\n",
    "                                'avgk_accuracy': avgk_acc_test_ba,\n",
    "                                'class_acc_dict': class_acc_test},\n",
    "               'params': args.__dict__}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"To run: python main.py --lr=0.05 --n_epochs=80 --k 1 3 5 10 --model=resnet50 --root=path_to_data --save_name_xp=xp1\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Provide your arguments here in this format:\n",
    "[\n",
    " argname1, argvalue1,\n",
    " argname2, argvalue2\n",
    "]\n",
    "\"\"\"\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Use CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "def run(config_replace={}):\n",
    "    # Get config\n",
    "    os.chdir(current_dir)\n",
    "    config = load_config_file()\n",
    "    for k in config_replace:\n",
    "        config[k] = config_replace[k] \n",
    "        # If resnet, make sure to also switch preloaded model location\n",
    "        if k == \"model\" and config_replace[k] == \"resnet50\":\n",
    "            config['preloaded_model_location'] = 'model/pretrained_model.pth'\n",
    "    # Convert to args\n",
    "    arg_list = get_args(config)\n",
    "    parser = argparse.ArgumentParser()\n",
    "    cli.add_all_parsers(parser)\n",
    "    args = parser.parse_args(args=arg_list)\n",
    "    # Run \n",
    "    if config['train_model'] == 'y':\n",
    "        train(args)\n",
    "    else:\n",
    "        predict(args)\n",
    "        \n",
    "def tuner():\n",
    "    # Define the search space for the hyperparameter\n",
    "    search_space = {\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"model\" : tune.choice([\"inception_v4\", \"resnet50\"]),\n",
    "        \"mu\":  tune.choice([0.0000, 0.0001]),\n",
    "        \"use_adam_optimizer\" : tune.choice([\"y\", \"n\"]),\n",
    "        \"use_focal_loss\" : tune.choice([\"y\", \"n\"]),\n",
    "        \"transfer_learning_freeze_weights\" : tune.choice([\"y\", \"n\"])\n",
    "    }\n",
    "    # Define the tuner and set early stopper scheduler\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(run, {\"cpu\": 4,  'gpu': 1}),\n",
    "        tune_config=tune.TuneConfig(num_samples=20, scheduler=ASHAScheduler(metric=\"mean_accuracy\", mode=\"max\")),\n",
    "        param_space=search_space,\n",
    "        \n",
    "    )\n",
    "    # Run tuner\n",
    "    results = tuner.fit()\n",
    "    # Plot by epoch the trials\n",
    "    ax = None  # This plots everything on the same plot\n",
    "    dfs = {result.log_dir: result.metrics_dataframe for result in results}\n",
    "    for d in dfs.values():\n",
    "        ax = d.mean_accuracy.plot(ax=ax, legend=False)\n",
    "    \n",
    "def main():\n",
    "    config = load_config_file()\n",
    "    if config['use_tuner'] == 'y':\n",
    "        tuner()\n",
    "    else:\n",
    "        run()\n",
    "        \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
