{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from timm) (1.10.2+cu113)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm) (0.11.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm) (4.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (1.22.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (9.0.1)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.6.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting monai\n",
      "  Using cached monai-0.9.1-202207251608-py3-none-any.whl (990 kB)\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.8/site-packages (from monai) (1.10.2+cu113)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from monai) (1.22.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->monai) (4.1.1)\n",
      "Installing collected packages: monai\n",
      "Successfully installed monai-0.9.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install timm\n",
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import yaml\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from IPython.display import display\n",
    "\n",
    "from utils import set_seed, load_model, save, get_model, update_optimizer, get_data\n",
    "from epoch import train_epoch, val_epoch, test_epoch\n",
    "from cli import add_all_parsers\n",
    "import greenstand_utils as gu  # GREENSTAND\n",
    "from monai.losses import FocalLoss # GREENSTAND\n",
    "\n",
    "\n",
    "def get_args(hyperparameter_config_file='hyperparameters.yaml'):\n",
    "    with open(hyperparameter_config_file) as file:\n",
    "        contents = yaml.safe_load(file)\n",
    "    new_args = []\n",
    "    for item in contents:\n",
    "        new_args.append('--' + item)\n",
    "        new_args.append(str(contents[item]))\n",
    "    return new_args\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    set_seed(args, use_gpu=torch.cuda.is_available())\n",
    "    \n",
    "    # Get Data  # GREENSTAND\n",
    "    g_args = vars(args) # GREENSTAND\n",
    "    g_args['prefixes'] = g_args['prefixes'].split(',') # GREENSTAND\n",
    "    train_loader, val_loader, test_loader, dataset_attributes = gu.sync_split_get_dataloaders(vars(args))  # GREENSTAND\n",
    "    print(f\"Dataset Attributes: {dataset_attributes}\") # GREENSTANDS\n",
    "    return\n",
    "\n",
    "    model = gu.load_preloaded_model(args, dataset_attributes)  # GREENSTAND - Get pretrained model if specified \n",
    "    criteria = FocalLoss(to_onehot_y=True) #BinaryFocalLossWithLogits(alpha=1.0) # GREENSTAND\n",
    "\n",
    "    if args.use_gpu:\n",
    "        torch.cuda.set_device(0)\n",
    "        model.cuda()\n",
    "        criteria.cuda()\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=args.mu) # GREENSTAND\n",
    "    # optimizer = SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=args.mu, nesterov=True)\n",
    "\n",
    "    # Containers for storing metrics over epochs\n",
    "    loss_train, acc_train, topk_acc_train = [], [], []\n",
    "    loss_val, acc_val, topk_acc_val, avgk_acc_val, class_acc_val = [], [], [], [], []\n",
    "\n",
    "    save_name = args.save_name_xp.strip()\n",
    "    save_dir = os.path.join(os.getcwd(), 'results', save_name)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    print('args.k : ', args.k)\n",
    "\n",
    "    lmbda_best_acc = None\n",
    "    best_val_acc = float('-inf')\n",
    "\n",
    "    for epoch in tqdm(range(args.n_epochs), desc='epoch', position=0):\n",
    "        t = time.time()\n",
    "        optimizer = update_optimizer(optimizer, lr_schedule=dataset_attributes['lr_schedule'], epoch=epoch)\n",
    "\n",
    "        loss_epoch_train, acc_epoch_train, topk_acc_epoch_train = train_epoch(model, optimizer, train_loader,\n",
    "                                                                              criteria, loss_train, acc_train,\n",
    "                                                                              topk_acc_train, args.k,\n",
    "                                                                              dataset_attributes['n_train'],\n",
    "                                                                              args.use_gpu)\n",
    "\n",
    "        loss_epoch_val, acc_epoch_val, topk_acc_epoch_val, \\\n",
    "        avgk_acc_epoch_val, lmbda_val = val_epoch(model, val_loader, criteria,\n",
    "                                                  loss_val, acc_val, topk_acc_val, avgk_acc_val,\n",
    "                                                  class_acc_val, args.k, dataset_attributes, args.use_gpu)\n",
    "\n",
    "        # save model at every epoch\n",
    "        save(model, optimizer, epoch, os.path.join(save_dir, save_name + '_weights.tar'))\n",
    "\n",
    "        # save model with best val accuracy\n",
    "        if acc_epoch_val > best_val_acc:\n",
    "            best_val_acc = acc_epoch_val\n",
    "            lmbda_best_acc = lmbda_val\n",
    "            save(model, optimizer, epoch, os.path.join(save_dir, save_name + '_weights_best_acc.tar'))\n",
    "\n",
    "        print()\n",
    "        print(f'epoch {epoch} took {time.time()-t:.2f}')\n",
    "        print(f'loss_train : {loss_epoch_train}')\n",
    "        print(f'loss_val : {loss_epoch_val}')\n",
    "        print(f'acc_train : {acc_epoch_train} / topk_acc_train : {topk_acc_epoch_train}')\n",
    "        print(f'acc_val : {acc_epoch_val} / topk_acc_val : {topk_acc_epoch_val} / '\n",
    "              f'avgk_acc_val : {avgk_acc_epoch_val}')\n",
    "\n",
    "    # load weights corresponding to best val accuracy and evaluate on test\n",
    "    load_model(model, os.path.join(save_dir, save_name + '_weights_best_acc.tar'), args.use_gpu)\n",
    "    loss_test_ba, acc_test_ba, topk_acc_test_ba, \\\n",
    "    avgk_acc_test_ba, class_acc_test, confuse = test_epoch(model, test_loader, criteria, args.k,\n",
    "                                                  lmbda_best_acc, args.use_gpu,\n",
    "                                                  dataset_attributes)\n",
    "    \n",
    "    print(\"Average test accuracy: {}\".format(avgk_acc_test_ba))\n",
    "    print(\"Average class accuracies: {}\".format(class_acc_test))\n",
    "    display(confuse)\n",
    "\n",
    "    # Save the results as a dictionary and save it as a pickle file in desired location\n",
    "\n",
    "    results = {'loss_train': loss_train, 'acc_train': acc_train, 'topk_acc_train': topk_acc_train,\n",
    "               'loss_val': loss_val, 'acc_val': acc_val, 'topk_acc_val': topk_acc_val, 'class_acc_val': class_acc_val,\n",
    "               'avgk_acc_val': avgk_acc_val,\n",
    "               'test_results': {'loss': loss_test_ba,\n",
    "                                'accuracy': acc_test_ba,\n",
    "                                'topk_accuracy': topk_acc_test_ba,\n",
    "                                'avgk_accuracy': avgk_acc_test_ba,\n",
    "                                'class_acc_dict': class_acc_test},\n",
    "               'params': args.__dict__}\n",
    "\n",
    "    with open(os.path.join(save_dir, save_name + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CUDA: True\n",
      "Seed:\t 1\n",
      "Checking to make sure all local files are present...\n",
      "Checking missing local files based on bucket: treetracker-training-images at prefix haiti/...\n",
      "No missing items locally.\n",
      "Checking missing local files based on bucket: treetracker-training-images at prefix herbarium/...\n",
      "No missing items locally.\n",
      "Checking missing local files based on bucket: treetracker-training-images at prefix internet_sourced/...\n",
      "No missing items locally.\n",
      "Checking missing local files based on bucket: treetracker-training-images at prefix freetown/...\n",
      "Found 8065 missing items locally. Downloading...\n",
      "Found 8065 objects...\n",
      "Writing file 0/8065\n",
      "Writing file 100/8065\n",
      "Writing file 200/8065\n",
      "Writing file 300/8065\n",
      "Writing file 400/8065\n",
      "Writing file 500/8065\n",
      "Writing file 600/8065\n",
      "Writing file 700/8065\n",
      "Writing file 800/8065\n",
      "Writing file 900/8065\n",
      "Writing file 1000/8065\n"
     ]
    }
   ],
   "source": [
    "\"\"\"To run: python main.py --lr=0.05 --n_epochs=80 --k 1 3 5 10 --model=resnet50 --root=path_to_data --save_name_xp=xp1\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Provide your arguments here in this format:\n",
    "[\n",
    " argname1, argvalue1,\n",
    " argname2, argvalue2\n",
    "]\n",
    "\"\"\"\n",
    "print(f\"Use CUDA: {torch.cuda.is_available()}\")\n",
    "arg_list = get_args()\n",
    "parser = argparse.ArgumentParser()\n",
    "add_all_parsers(parser)\n",
    "args = parser.parse_args(args=arg_list)\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
