lr: .001 # learning rate to use
n_epochs: 10 # How many epochs to run
k: 1 # value of k for computing the topk loss and computing topk accuracy
model: resnet50 # Select the model you want to train on (other choices: 'resnet50', 'densenet121', 'densenet169', 'mobilenet_v2', 'inception_resnetv2')
root: ../../../data/plantnet_300K/ # specify the root location of the data
save_name_xp: xp1 # name of the saving file
seed: 1 # declare the random seed for the training
batch_size: 16 # how many images in each batch
mu: 0 # weight decay parameter
size_image: 256 # default what size the images will be resized to
num_workers: 2 # number of workers for the data loader. Default is one. You can bring it up. If you have memory errors, set it to 1

# Greenstand specific
visualize: True # set to True if you want to visualize data and model output
bucket: treetracker-training-images # this is the bucket where the greenstand images are in S3
prefixes: haiti/,herbarium/,internet_sourced/,freetown/ # csv. list all of the prefixes within that bucket that you want to sync. The assumption is class labels are a sub-directory, and images are within the sub-directories
sub_dir_limit: 1000 # Ensures per prefix per species, we do not download more than this number of images
local_path: ../../../data/treetracker-training-images  # this is where the greenstand images will reside on your local machine
train_test_split: 0.8  # this is the first split done, between training and test
train_val_split: 0.8 # this split is done on the already split training data to make train and val
metadata_file: metadata.json # this will contain the information on the image split between train, val, and test
preloaded_model_location: model/pretrained_model.pth # leave blank to use fresh model, else this will load the pretrained one here